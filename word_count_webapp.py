import streamlit as st
import string
from collections import Counter
import pandas as pd

# é¡µé¢åŸºç¡€è®¾ç½®
st.set_page_config(
    page_title="è‹±æ–‡å•è¯ç»Ÿè®¡å·¥å…·ï¼ˆå¤šæ–‡ä»¶ç‰ˆï¼‰",
    page_icon="ğŸ“–",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
    <style>
    .stMetric {background-color: #f0f2f6; padding: 15px; border-radius: 8px;}
    .stFileUploader > label {font-size: 16px; font-weight: 500;}
    </style>
    """, unsafe_allow_html=True)

# æ ¸å¿ƒç»Ÿè®¡å‡½æ•°
def count_english_words(text):
    translator = str.maketrans('', '', string.punctuation)
    clean_text = text.lower().translate(translator)
    words = [word.strip() for word in clean_text.split() if word.strip()]
    
    total = len(words)
    unique = len(set(words))
    freq = Counter(words)
    freq_df = pd.DataFrame(freq.items(), columns=["è‹±æ–‡å•è¯", "å‡ºç°æ¬¡æ•°"]).sort_values(by="å‡ºç°æ¬¡æ•°", ascending=False).reset_index(drop=True)
    
    return {"total": total, "unique": unique, "frequency_df": freq_df}

# ç½‘é¡µç•Œé¢
st.title("ğŸ“ è‹±æ–‡å•è¯ç»Ÿè®¡å¹³å°ï¼ˆå¤šæ–‡ä»¶æ‰¹é‡ç‰ˆï¼‰")
st.markdown("### ä¸Šä¼ å¤šä¸ª `.txt` è‹±æ–‡æ–‡ä»¶ï¼Œè‡ªåŠ¨ç»Ÿè®¡æ¯ä¸ªæ–‡ä»¶çš„å•è¯æ•°")
st.divider()

# å¤šæ–‡ä»¶ä¸Šä¼ ç»„ä»¶
uploaded_files = st.file_uploader(
    "é€‰æ‹©å¤šä¸ªè‹±æ–‡æ–‡æœ¬æ–‡ä»¶ï¼ˆä»…æ”¯æŒ .txtï¼‰",
    type=["txt"],
    accept_multiple_files=True,  # å¼€å¯å¤šæ–‡ä»¶ä¸Šä¼ 
    help="å¯åŒæ—¶é€‰æ‹©å¤šä¸ª.txtæ–‡ä»¶ï¼Œè‡ªåŠ¨æ‰¹é‡ç»Ÿè®¡"
)

if uploaded_files:
    # å­˜å‚¨æ‰€æœ‰æ–‡ä»¶çš„ç»Ÿè®¡ç»“æœ
    all_results = []
    total_all_files = 0  # æ‰€æœ‰æ–‡ä»¶æ€»å•è¯æ•°
    unique_all_files = set()  # æ‰€æœ‰æ–‡ä»¶çš„å”¯ä¸€å•è¯é›†åˆ

    with st.spinner("æ­£åœ¨æ‰¹é‡ç»Ÿè®¡æ‰€æœ‰æ–‡ä»¶..."):
        for file in uploaded_files:
            try:
                # è¯»å–æ–‡ä»¶
                try:
                    text = file.read().decode("utf-8")
                except UnicodeDecodeError:
                    text = file.read().decode("gbk")
                
                # ç»Ÿè®¡å½“å‰æ–‡ä»¶
                stats = count_english_words(text)
                total_all_files += stats["total"]
                unique_all_files.update(stats["frequency_df"]["è‹±æ–‡å•è¯"].tolist())
                
                # è®°å½•å½“å‰æ–‡ä»¶ç»“æœ
                all_results.append({
                    "æ–‡ä»¶å": file.name,
                    "æ€»å•è¯æ•°": stats["total"],
                    "å”¯ä¸€å•è¯æ•°": stats["unique"]
                })

                # å±•ç¤ºå•ä¸ªæ–‡ä»¶çš„è¯¦ç»†ç»“æœ
                st.subheader(f"ğŸ“„ æ–‡ä»¶ï¼š{file.name}")
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("æ€»å•è¯æ•°", stats["total"])
                with col2:
                    st.metric("å”¯ä¸€å•è¯æ•°", stats["unique"])
                st.dataframe(
                    stats["frequency_df"],
                    use_container_width=True,
                    hide_index=True,
                    column_config={"è‹±æ–‡å•è¯": st.column_config.TextColumn(width="medium")}
                )
                st.divider()

            except Exception as e:
                st.error(f"æ–‡ä»¶ {file.name} å¤„ç†å¤±è´¥ï¼š{str(e)}", icon="âš ï¸")

        # å±•ç¤ºæ‰€æœ‰æ–‡ä»¶çš„æ±‡æ€»ç»“æœ
        st.subheader("ğŸ“Š æ‰€æœ‰æ–‡ä»¶æ±‡æ€»ç»Ÿè®¡")
        col_a, col_b = st.columns(2)
        with col_a:
            st.metric("æ‰€æœ‰æ–‡ä»¶æ€»å•è¯æ•°", total_all_files)
        with col_b:
            st.metric("æ‰€æœ‰æ–‡ä»¶å”¯ä¸€å•è¯æ•°", len(unique_all_files))
        
        # å±•ç¤ºå„æ–‡ä»¶ç»Ÿè®¡è¡¨æ ¼
        st.dataframe(
            pd.DataFrame(all_results),
            use_container_width=True,
            hide_index=True,
            column_config={
                "æ–‡ä»¶å": st.column_config.TextColumn(width="medium"),
                "æ€»å•è¯æ•°": st.column_config.NumberColumn(),
                "å”¯ä¸€å•è¯æ•°": st.column_config.NumberColumn()
            }
        )

else:
    st.info("ğŸ‘‰ å¯åŒæ—¶é€‰æ‹©å¤šä¸ª.txtæ–‡ä»¶ä¸Šä¼ ï¼Œè‡ªåŠ¨æ‰¹é‡ç»Ÿè®¡", icon="ğŸ’¡")
